{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains various examples of how to read tabulated data in Python.\n",
    "\n",
    "Date Created: Fall 2016 \n",
    "Last Modified: Oct 16 2017 \n",
    "Humans Responsible: The Prickly Pythons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data files in different formats (and save them) in python\n",
    "\n",
    "### Starting with Ascii files!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In test_data/ there is a text file called spectrum2.dat with \n",
    "# data that we want to import into python. \n",
    "# (spectrum2.dat is a model stellar spectrum from starburst99 for \n",
    "# a group of stars with 0.7 x solar metallicity, \n",
    "# 1e4 solar masses population, Kroupa IMF and a starburst 1e6 years ago)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data into numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# http://docs.scipy.org/doc/numpy/reference/generated/numpy.loadtxt.html\n",
    "spec_nparray    =   np.loadtxt('test_data/spectrum.dat',skiprows=6)\n",
    "print(type(spec_nparray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of this numpy array will be determined by number of columns and rows in your data:\n",
    "print(spec_nparray.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And if you want to extract e.g. wavelength, you need to remember the column index, in this case 0:\n",
    "wavelength_A = spec_nparray[:,1]\n",
    "print(wavelength_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default, numbers are loaded with float 64bit precision: \n",
    "wavelength_A.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The genfromtxt function from numpy is a bit more flexible\n",
    "# http://docs.scipy.org/doc/numpy/reference/generated/numpy.genfromtxt.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_nparray2    =   np.genfromtxt('test_data/spectrum.dat',skip_header=6,\\\n",
    "                    names=['t_yr','wavelength_A','L_tot','L_stellar','L_nebular'])\n",
    "print(type(spec_nparray2))\n",
    "print(spec_nparray[0,1])\n",
    "print(spec_nparray2['wavelength_A'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to change one of the wavelengths into something that is not a number (like %%%) and you will see that genfromtxt \n",
    "# can handle this with the keywords missing_values='%%%',filling_values=-1:\n",
    "spec_nparray2    =   np.genfromtxt('test_data/spectrum_nan.dat',skip_header=6,\\\n",
    "                    names=['t_yr','wavelength_A','L_tot','L_stellar','L_nebular'],\\\n",
    "                    missing_values='%%%',filling_values=-1)\n",
    "print(spec_nparray2['wavelength_A'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But loadtxt will crash:\n",
    "spec_nparray    =   np.loadtxt('test_data/spectrum_nan.dat',skiprows=6)\n",
    "print(type(spec_nparray2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data into pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Typically, a smarter way (if you are essentially loadin a matrix) \n",
    "# is to load the data directly into a pandas dataframe\n",
    "# http://pandas.pydata.org/pandas-docs/stable/dsintro.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "names=['t_yr','wavelength_A','L_tot','L_stellar','L_nebular']\n",
    "spec_dataframe    =   pd.read_table('test_data/spectrum.dat',\\\n",
    "                names=names,\\\n",
    "                skiprows=6,sep=r\"\\s*\",engine='python')    \n",
    "print(type(spec_dataframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_dataframe['t_yr'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot spectrum\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['xtick.labelsize'] = 15\n",
    "mpl.rcParams['ytick.labelsize'] = 15\n",
    "fig          =   plt.figure(0,figsize=(10,5))\n",
    "ax1          =   fig.add_axes([0.15,0.1,0.75,0.8])\n",
    "ax1.set_ylim(31,39)\n",
    "ax1.set_xlim(1e2,1e6)\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_xlabel('Wavelength [AA]',fontsize=15)\n",
    "ax1.set_ylabel('log flux [erg/s/AA]',fontsize=15)\n",
    "ax1.set_title('1e4 M$_{\\odot}$ of stars with Z=0.008 after 1e6 yr',fontsize=15)#+str(t1)+' yr')\n",
    "#ax1.plot(spec_nparray[:,1],spec_nparray[:,2],'b')\n",
    "#ax1.plot(spec_nparray2['wavelength'],spec_nparray2['L_tot'],'b')\n",
    "ax1.plot(spec_dataframe['wavelength_A'],spec_dataframe['L_tot'],'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pandas to save a dataframe with pickle:\n",
    "spec_dataframe.to_pickle('test_data/spec_dataframe_pickle') # no extension\n",
    "load_spec_dataframe_pickle = pd.read_pickle('test_data/spec_dataframe_pickle')\n",
    "load_spec_dataframe_pickle['t_yr'][0] # test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fits files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In test_data/ there is a file called cloud.fits with data that we \n",
    "# want to import into python. \n",
    "# (cloud.fits is a simulated HCO+ data cube of a cloud, calculated \n",
    "# with RT code LIME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read fits file into list-like Python opject with the fits function from the astropy module\n",
    "from astropy.io import fits\n",
    "fits_file = fits.open('test_data/cloud.fits')\n",
    "print(type(fits_file))\n",
    "fits_file.info() # get basic info, like number of header cards and dimensions of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fits_file[0].header) # display all header cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can extract general info from the header cards like this:\n",
    "imgres = fits_file[0].header['CDELT2']\n",
    "print('Image resolution: ' + str(imgres) + ' degrees')\n",
    "npix = fits_file[0].header['NAXIS3']\n",
    "print('Number of pixels on each side: ' + str(npix))\n",
    "velres = fits_file[0].header['CDELT3']\n",
    "print('Velocity resolution: ' + str(velres) + 'm/s')\n",
    "fits_file[0].header['CDELT2']=2.0\n",
    "print('Image resolution: ' + str(imgres) + ' degrees')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And the actual data is an attribute of data[0]\n",
    "HCO_flux = fits_file[0].data # [velocity channels, x axis, y axis]\n",
    "print(HCO_flux[0,50,50])\n",
    "mom0 = HCO_flux.sum(axis=0)*velres/1000 # moment 0 map, Jy*km/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contour plot of data cube\n",
    "import matplotlib.cm as cm\n",
    "fig         =   plt.figure(1,figsize=(9,9))\n",
    "ax1         =   fig.add_axes([0.15,0.1,0.75,0.8])\n",
    "ax1.set_xlabel(\"x ['']\",fontsize=15)\n",
    "ax1.set_ylabel(\"y ['']\",fontsize=15)\n",
    "ax1.set_title(\"Moment 0 map of HCO$^+$ gas cloud\",fontsize=15)\n",
    "x1 = imgres*(np.arange(npix)-npix/2) # image axis\n",
    "xmax = max(x1)\n",
    "im = ax1.imshow(mom0,interpolation='bilinear',origin='lower',cmap=cm.hot,extent=(-xmax,xmax,-xmax,xmax),vmax=120)\n",
    "cax = fig.add_axes([0.9,0.1,0.05,0.8])\n",
    "cbar = plt.colorbar(im,cax=cax)\n",
    "cbar.set_label('Jy km/s',size=20)\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving python data for later with numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Say you have a numpy array that you want to save to a file and load later. \n",
    "# One way to do so is with numpy:\n",
    "np.save('test_data/spec_nparray',spec_nparray) # will get a 'npy' extension\n",
    "load_spec_nparray = np.load('test_data/spec_nparray.npy')\n",
    "load_spec_nparray[0,0] # test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also use pickle! Or cPickle, which is pickle written in C, \n",
    "# with several advantages.\n",
    "import cPickle as pickle\n",
    "pickle.dump(spec_nparray,open('test_data/spec_nparray_pickle','wb')) # no extension\n",
    "# 'wb' is the protocol and means to write to binary format\n",
    "load_spec_nparray = pickle.load(open('test_data/spec_nparray_pickle','rb'))\n",
    "load_spec_nparray[0,0] # test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But the to_pickle attribute is specific to pandas and will not work on say a numpy array:\n",
    "spec_nparray.to_pickle('test_data/spec_dataframe_pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
